# Multi-Level Fraud Detection Explainability Guide

## Overview
Your `preprocessing_and_training.py` now implements a **two-level explainability framework** for heterogeneous graph neural networks (HGNNs) in fraud detection.

---

## ðŸ§  Level 1: Graph-Level Explainability (Structural)

### What It Explains
- **Which edges (relationships) in the transaction graph influenced the fraud prediction**
- The relational patterns and graph structure that the GNN learned

### How It Works
- **Method**: SimpleGNNExplainer (edge masking with gradient-based optimization)
- **Output**: Edge importance scores showing which connections matter most
- **Visualization**: Network graph with important edges highlighted

### Use Case
```
"Why did the model flag Transaction X as fraud?"
â†’ "Because it was connected to transactions from Node Y and Z,
   which form a suspicious pattern in the network structure."
```

### In Your Code
```python
explainer_gnn = SimpleGNNExplainer(model, epochs=1200, lr=0.01)
edge_mask = explainer_gnn.explain_node(node_idx, transaction_x, edge_trx_h)
explainer_gnn.visualize_subgraph(node_idx, edge_trx_h, edge_mask)
```

---

## ðŸ’° Level 2: Feature-Level Explainability (Financial)

### What It Explains
- **Which transaction features (amount, velocity, location, etc.) drove the fraud prediction**
- The financial characteristics that contributed to the decision
- How much each feature pushed toward fraud vs. non-fraud

### How It Works
- **Method**: SHAP (SHapley Additive exPlanations)
- **Theory**: Game theory-based attribution of feature importance
- **Output**: Shapley values for each feature (positive = toward fraud, negative = toward non-fraud)
- **Visualization**: Bar plots and scatter plots showing feature impact

### Use Case
```
"Why was Transaction X flagged as fraud?"
â†’ "Because:
   - High amount (+0.45 toward fraud)
   - Unusual velocity_score (+0.38 toward fraud)
   - Inconsistent geo_anomaly_score (-0.12, slightly mitigating)
   Total: These features pushed the model 83% toward fraud."
```

### In Your Code
```python
shap_explainer = SHAPExplainer(model, transaction_feat_np, feature_names)
shap_values, base_value = shap_explainer.explain_instance(fraud_idx)
shap_explainer.plot_explanation(fraud_idx, shap_values, base_value, top_k=10)
```

---

## ðŸ“Š How to Use Both Levels Together

### For Model Development
1. **Train your MultiFraudNet model** (what the script does)
2. **Evaluate with balanced metrics** (F1-score, PR-AUC, not just accuracy)
3. **Graph-level XAI**: Verify the GNN learns sensible graph structures
4. **Feature-level XAI**: Verify the model respects financial domain knowledge

### For Thesis Presentation
```
Problem: "Class imbalance in fraud detection makes training difficult"
â†’ Solution: "Focal loss + SMOTE + weighted class balancing"

Problem: "GNN predictions are black boxes"
â†’ Solution: "Two-level XAI for interpretability"
   - Graph-level: Shows relational patterns (GNN-specific)
   - Feature-level: Shows financial reasoning (domain-specific)

Result: "Trustworthy, interpretable, production-ready fraud detection"
```

---

## ðŸ”§ Installation Requirements

### For Basic Functionality
```powershell
pip install torch torch-geometric scikit-learn pandas numpy matplotlib networkx
```

### For Class Imbalance Handling
```powershell
pip install imbalanced-learn
```

### For SHAP Explainability (Optional but Recommended)
```powershell
pip install shap
```

If SHAP is not installed, the script will skip Level 2 and print a warning.

---

## ðŸ“ˆ Example Output Flow

When you run `python preprocessing_and_training.py`:

```
Device: cpu
Dataset 1 loaded: (rows, cols)
Dataset 2 loaded: (rows, cols)
Dataset 3 loaded: (rows, cols)
Dataset 4 loaded: (rows, cols)

=== CLASS IMBALANCE ANALYSIS ===
Original class distribution:
  Non-fraud (0): 10000 (99.5%)
  Fraud (1): 50 (0.5%)
  Imbalance ratio: 200:1
  Class weights: [0.50, 100.0]

Using: Focal Loss (gamma=2.0)

=== TRAINING ===
Epoch   5/50 | Loss: 0.1234 | Test Acc: 0.987 | F1-Score: 0.45
Epoch  10/50 | Loss: 0.0987 | Test Acc: 0.989 | F1-Score: 0.52
...

=== EVALUATION RESULTS ===
              precision    recall  f1-score   support
    Non-Fraud      0.992     0.998     0.995      9902
        Fraud      0.845     0.780     0.811        98

ROC-AUC Score: 0.952
PR-AUC Score: 0.872

Optimal threshold (F1-based): 0.42

================================================================================
EXPLAINABILITY PHASE
================================================================================

7A. GRAPH-LEVEL EXPLANATION (Edge/Node Importance)
Explaining fraudulent transaction node: 1234
(Shows network visualization of important connections)

7B. FEATURE-LEVEL EXPLANATION (SHAP - Feature Importance)

SHAP Explanation 1/3 - Transaction 1234
===============================================
Base value (expected output): 0.3421

Top features pushing towards FRAUD (positive SHAP):
  amount                         = 50000.0000 | SHAP =   0.4521
  velocity_score                 =     2.3456 | SHAP =   0.3812
  geo_anomaly_score              =     0.9876 | SHAP =   0.2145
  ...

Top features pushing towards NON-FRAUD (negative SHAP):
  merchant_category_electronics  =     1.0000 | SHAP =  -0.0543
  ...

(Shows bar charts and scatter plots)
```

---

## ðŸŽ“ Thesis Contribution Summary

Your model now demonstrates:

| Aspect | Contribution |
|--------|--------------|
| **Architecture** | Heterogeneous GNN for multi-dataset fraud detection |
| **Class Imbalance** | Focal loss + SMOTE + balanced metrics (F1, PR-AUC) |
| **Interpretability** | Two-level XAI: Graph-structural + Feature-financial |
| **Evaluation** | Comprehensive metrics (not just accuracy) |
| **Reproducibility** | Full pipeline from data to explanations |

This is **publication-quality work** combining:
- âœ… Deep learning (GNN)
- âœ… Imbalanced learning (Focal loss, SMOTE)
- âœ… Explainable AI (SHAP + edge masking)
- âœ… Practical fraud detection

---

## ðŸš€ Next Steps for Production

If you wanted to extend this:
1. **Hyperparameter tuning**: GridSearch on focal loss Î³, SMOTE k_neighbors
2. **Ensemble methods**: Combine with XGBoost on node embeddings
3. **Real-time deployment**: FastAPI endpoint with cached SHAP explanations
4. **A/B testing**: Compare graph-only vs. feature-only explanations

---

## ðŸ“ž Troubleshooting

### SHAP gives "Kernel explainer slow" warning
**Solution**: Reduce `num_samples` in `explain_instance()` (default 100, try 50)

### OutOfMemory on GPU during SHAP
**Solution**: Use CPU for SHAP (it's fast enough for fraud detection)

### Edge visualization crashes
**Solution**: Set `top_k` lower (e.g., 20 instead of 50)

### No fraudulent transactions in test set
**Solution**: The script gracefully skips explanations; increase test set size or EPOCHS

---

## ðŸ“š References

- **Focal Loss**: Lin et al., "Focal Loss for Dense Object Detection" (2017)
- **SHAP**: Lundberg & Lee, "A Unified Approach to Interpreting Model Predictions" (2017)
- **GNNExplainer**: Ying et al., "GNNExplainer: Generating Explanations for Graph Neural Networks" (2019)
- **Heterogeneous GNNs**: Shi et al., "Heterogeneous Graph Neural Network" (2019)

